{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQi9qaU8mCoPla4DmdyPv+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RuthBiney/BCI-Ampe_Game/blob/main/BCI_Ampe_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 1: Set Up Your Development Environment\n",
        "###1. Install Python:\n",
        "*  Download and install Python (version 3.8 or higher) from python.org.\n",
        "\n",
        "###2. Install Required Libraries:\n",
        "*   Open a terminal or command prompt and install the following libraries:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pirgzS5L4ger"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTU2WQev4RlO"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow keras numpy pandas scipy mne matplotlib seaborn plotly"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 2: Load and Preprocess the Dataset\n",
        "###1. Download the Dataset:\n",
        "*   Use the dataset I created myself whicch will be provided later\n",
        "\n",
        "###2. Load the Dataset\n",
        "*   Use Python to load the dataset\n"
      ],
      "metadata": {
        "id": "vf78cg_T5RBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mne\n",
        "\n",
        "# Load EEG data using MNE-Python\n",
        "raw = mne.io.read_raw_gdf('path_to_dataset.gdf', preload=True)"
      ],
      "metadata": {
        "id": "W09_D5bD6O2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Preprocess the Data:\n",
        "*   Filter the data to remove noise and artifacts:"
      ],
      "metadata": {
        "id": "vbMkVilQ6h9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw.filter(7., 30., fir_design='firwin')  # Bandpass filter (7-30 Hz)"
      ],
      "metadata": {
        "id": "1osEbX4R6rIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Normalize the data:\n",
        "\n"
      ],
      "metadata": {
        "id": "d13wR19a62gE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Extract EEG data\n",
        "eeg_data = raw.get_data().T  # Shape: (n_samples, n_channels)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "eeg_data = scaler.fit_transform(eeg_data).T  # Shape: (n_channels, n_samples)"
      ],
      "metadata": {
        "id": "QAgDAqCH6-qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Segment the data into time windows:\n",
        "\n"
      ],
      "metadata": {
        "id": "nOpyTVd27DZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 128  # 1-second window at 128 Hz\n",
        "segments = np.array([eeg_data[:, i:i+window_size] for i in range(0, eeg_data.shape[1] - window_size, window_size)])\n",
        "\n",
        "# Print the shape of the segmented data\n",
        "print(segments.shape)  # Should be (n_segments, n_channels, window_size)"
      ],
      "metadata": {
        "id": "FSawKQ_e7LEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Prepare Labels:\n",
        "\n",
        "  Extract the labels for each segment (e.g., left hand, right hand, foot, tongue):"
      ],
      "metadata": {
        "id": "Z3UMU44k9yI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Assuming labels are stored in a separate file\n",
        "labels = np.load('path_to_labels.npy')  # Load labels\n",
        "labels = labels[:segments.shape[0]]  # Ensure labels match the number of segments"
      ],
      "metadata": {
        "id": "MpGpyqfk-I9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Save the Preprocessed Data\n",
        "Save the preprocessed data and labels for later use:"
      ],
      "metadata": {
        "id": "kbOe1woJ-Ze_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('preprocessed_eeg_data.npy', segments)\n",
        "np.save('labels.npy', labels)"
      ],
      "metadata": {
        "id": "Rl1QPEic-dCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3: Verify the Preprocessed Data\n",
        "Before moving to model development, verify that the preprocessed data is correct:\n",
        "###1. Check the shape of the segment data:"
      ],
      "metadata": {
        "id": "RYLzVjg9-oB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(segments.shape)  # Should be (n_segments, n_channels, window_size)"
      ],
      "metadata": {
        "id": "ltDcgTvI-63v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Visualize a sample segment:"
      ],
      "metadata": {
        "id": "ulVy7uUs_AF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(segments[0].T)  # Plot the first segment\n",
        "plt.title(\"Sample EEG Segment\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LXEo2SqU_I9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4: Design the Hybrid CNN-RNN Model\n",
        "###1. Import Libraries:\n",
        "First, import the necessary libraries for building the model:"
      ],
      "metadata": {
        "id": "JLNUhWCY7Ofv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Flatten, Reshape"
      ],
      "metadata": {
        "id": "2L1gaw_l7c6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Define the Model:\n",
        "We’ll create a hybrid CNN-RNN model using TensorFlow/Keras. Here’s the step-by-step process:\n",
        "\n",
        "###1. Input Layer:\n",
        "*   Reshape the input data to match the expected format for the CNN (e.g., (n_channels, window_size, 1)).\n",
        "\n",
        "###2. CNN Layers:\n",
        "*   Use Conv2D layers to extract spatial features from the EEG signals.\n",
        "*   Add MaxPooling2D layers to reduce the dimensionality of the features.\n",
        "\n",
        "###3. RNN Layers:\n",
        "*   Use LSTM layers to capture temporal dependencies in the EEG data.\n",
        "\n",
        "###4. Output Layer:\n",
        "*   Use a Dense layer with a softmax activation function to classify the motor imagery tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "2GNTEzfX7f2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Reshape input for CNN (n_channels, window_size, 1)\n",
        "model.add(Reshape((segments.shape[1], segments.shape[2], 1), input_shape=(segments.shape[1], segments.shape[2])))\n",
        "\n",
        "# CNN Layers\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))  # 32 filters, 3x3 kernel\n",
        "model.add(MaxPooling2D((2, 2)))  # Max pooling with 2x2 window\n",
        "model.add(Flatten())  # Flatten the output for RNN input\n",
        "\n",
        "# Reshape for RNN (n_timesteps, n_features)\n",
        "model.add(Reshape((-1, 32)))  # Reshape to (n_timesteps, n_features)\n",
        "\n",
        "# RNN Layers\n",
        "model.add(LSTM(64, return_sequences=True))  # 64 LSTM units, return sequences\n",
        "model.add(LSTM(32))  # 32 LSTM units\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(4, activation='softmax'))  # 4 classes for motor imagery tasks"
      ],
      "metadata": {
        "id": "rRUawUZN7tre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Compile the Model:\n",
        "Compile the model by specifying the optimizer, loss function, and evaluation metric:"
      ],
      "metadata": {
        "id": "V4jdpXfT7y1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xQHfjUpL73k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Print the Model Summary\n",
        "Print a summary of the model to verify its architecture:"
      ],
      "metadata": {
        "id": "ORQaiaQMFpzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "i12YEYbSFt2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 5: Prepare the Data for Training\n",
        "Before training the model, ensure the data is in the correct format:\n",
        "\n",
        "###1. Convert Labels to Categorical:\n",
        "*   Use one-hot encoding for the labels:"
      ],
      "metadata": {
        "id": "heG0UgQR8CE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, num_classes=4)\n",
        "y_test = to_categorical(y_test, num_classes=4)"
      ],
      "metadata": {
        "id": "MPlQ03m78R2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Split the Data:\n",
        "*   Split the preprocessed data into training and testing sets (if not already done):\n"
      ],
      "metadata": {
        "id": "lDQP1RLh8jGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(segments, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zRYLd-yn8ow0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 6: Train the Model\n",
        "Train the model using the preprocessed data:"
      ],
      "metadata": {
        "id": "NdLEwnIi8rC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "P-qOGS2C8uwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 7: Evaluate the Model\n",
        "Evaluate the model’s performance on the test set:"
      ],
      "metadata": {
        "id": "CHBzFWcUHC2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "3ZVYTLmgHGHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 8: Visualize Training Results\n",
        "Plot the training and validation accuracy/loss to analyze the model’s performance:"
      ],
      "metadata": {
        "id": "kvq3vxRQHJFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uVVz_hUBHN6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}